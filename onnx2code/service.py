import tempfile
from pathlib import Path
from subprocess import call
from typing import Any
from multiprocessing import shared_memory
import subprocess
import numpy as np
import numpy.typing as npt

from .result import ModelResult


class ModelService:
    """
    Allows using a model generated by onnx2code in a convenient way

    Used for testing and evaluation
    """

    def __init__(self, result: ModelResult):
        self.result = result

    def __enter__(self) -> "ModelService":
        """
        Compiles the model and starts a subprocess
        """
        self.temp_dir = tempfile.TemporaryDirectory()

        self._compile()
        self._boot()

        return self

    def _compile(self) -> None:
        # temp_dir = Path(self.temp_dir.name)

        temp_dir = Path("tmp/")
        temp_dir.mkdir(exist_ok=True)

        cpp_file = temp_dir / "model.c"
        hpp_file = temp_dir / "model.h"
        asm_file = temp_dir / "model.asm"
        asm_object = temp_dir / "model-asm.o"
        svc_file = Path(__file__).parent / "service.c"
        self.weights_file = temp_dir / "weights.bin"
        self.service_executable = temp_dir / "service"

        self.result.weights.tofile(self.weights_file)

        for file, content in [
            (cpp_file, self.result.source_cpp),
            (hpp_file, self.result.source_hpp),
            (asm_file, self.result.source_asm),
        ]:
            with open(file, "w") as f:
                f.write(content)

        compile_asm_cmd = [
            "nasm",
            "-f",
            "elf64",
            str(asm_file),
            "-o",
            str(asm_object),
            "-g",
        ]
        compile_svc_cmd = [
            "gcc",
            "-m64",  # 64 bit env
            str(asm_object),
            str(hpp_file),
            str(cpp_file),
            str(svc_file),
            "-o",
            str(self.service_executable),
            "-O0",
            "-g",
            "-fsanitize=address",
            "-std=c99",
            "-Wall",
        ]

        # TODO: hacer una funcion que corra el comando y parse el output
        #       si falla poner el output en la Exception
        #       y todo el resto del output tirarlo (warning etc) asi no poluciona
        if call(compile_asm_cmd) != 0:
            raise Exception("failure compiling asm")
        if call(compile_svc_cmd) != 0:
            raise Exception("failure compiling service")

    def _boot(self) -> None:
        """
        Creates the shared memory blocks and starts the service subprocess
        """
        self.shm_inputs = shared_memory.SharedMemory(
            "/onnx2code-inputs", create=True, size=self.result.inputs_size * 4
        )
        self.shm_outputs = shared_memory.SharedMemory(
            "/onnx2code-outputs", create=True, size=self.result.outputs_size * 4
        )
        self.inputs_buffer: npt.NDArray[np.float32] = np.ndarray(
            self.result.inputs_size, dtype=np.float32, buffer=self.shm_inputs.buf
        )
        self.outputs_buffer: npt.NDArray[np.float32] = np.ndarray(
            self.result.outputs_size, dtype=np.float32, buffer=self.shm_outputs.buf
        )
        self.process = subprocess.Popen(
            [self.service_executable, self.weights_file],
            stdin=subprocess.PIPE,
            stdout=subprocess.PIPE,
        )

    def inference(
        self, inputs: dict[str, npt.NDArray[np.float32]]
    ) -> list[npt.NDArray[np.float32]]:
        """
        Runs the model with the given inputs

        TODO: support more than one input and output
        """
        assert len(inputs) == len(self.result.input_shapes)

        # load inputs into shared memory
        self.inputs_buffer[:] = list(inputs.values())[0].reshape(-1)

        # signal service that inputs are ready
        assert self.process.stdin and self.process.stdout
        self.process.stdin.write("1".encode())
        self.process.stdin.flush()
        # wait for service to finish inference
        self.process.stdout.read(1)

        # read outputs from shared memory
        return [self.outputs_buffer.reshape(list(self.result.ouput_shapes.values())[0])]

    def __exit__(self, _1: Any, _2: Any, _3: Any) -> None:
        # exit service
        self.process.terminate()

        # release shared memory
        self.shm_inputs.unlink()
        self.shm_outputs.unlink()

        # remove compilation files
        self.temp_dir.cleanup()
